#!/usr/bin/python

from __future__ import print_function

import os
import time
import sqlite3
# import collections

import classad


#DONE_IF_NOT_SEEN_AFTER = 1 * 60 * 60;
DONE_IF_NOT_SEEN_AFTER = 60

want_pslot_attrs = [
    'DaemonStartTime',
    'Cpus',
    'GLIDEIN_Site',
    'GLIDEIN_ResourceName',
    'Machine',
    'Name',
    'SlotType',
    'ChildName',
]

want_dslot_attrs = [
    'CPUsUsage',
    'MemoryUsage',
]

want_attrs = want_pslot_attrs + want_dslot_attrs

send_attrs = [
    'StartTime',     # DaemonStartTime
    'EndTime',       # <last seen time, after gone for N hours>
    'WallDuration',  # <EndTime or Now> - <StartTime>
    'CpuDuration',   #(User): CPUsUsage * <polling interval in minutes>
                     # + <previous CPU total> across all dynamic slots carved
                     #                        off from the partitionable slot
    'Processors',    # Cpus
    'Memory',        # MemoryUsage
    'VOName',        # "OSG" (fixed)
    'Site',          # GLIDEIN_Site (or GLIDEIN_ResourceName)
    'MachineName',   # Machine
]



def coljoin(cols):
    return "\n, ".join(cols)

def fmt_coljoin(fmt, cols):
    return coljoin(map(fmt.format, cols))


schema_sql = [
    """
    create table jobs
    ( last_updated
    , {jobs_cols}
    , total_cpu
    , unique (Name)
    );
    """.format(jobs_cols=coljoin(want_attrs)),


    """
    create table slots
    ( pslot
    , dslot
    , unique (pslot, dslot)
    , unique (dslot)
    );
    """,


    """
    create table inbox
    ( next_updated
    , {inbox_cols}
    , unique (Name)
    );
    """.format(inbox_cols=coljoin(want_attrs)),


    """
    create table outbox
    ( id integer primary key autoincrement
    , {outbox_cols}
    );
    """.format(outbox_cols=coljoin(send_attrs)),


    """
    create view pslot_totals as
    select p.next_updated
         , {pslot_cols}
         , {dslot_cols}
      from inbox p
      join slots s
        on p.name = s.pslot
--     and p.SlotType = 'Partitionable'
      join inbox d
        on d.name = s.dslot
--     and d.SlotType = 'Dynamic'
     group by p.name
       ;
    """.format(pslot_cols=fmt_coljoin("p.{}", want_pslot_attrs),
               dslot_cols=fmt_coljoin("sum(d.{0}) as {0}", want_dslot_attrs)),


    """
    create view updates as
    select a.*
         , b.name                      as b_name
         , b.next_updated
         , b.CPUsUsage                 as next_CPUsUsage
         , b.MemoryUsage               as next_MemoryUsage
         , next_updated - last_updated as elapsed_interval
      from jobs a
--    left join inbox b
      left join pslot_totals b
        on a.name = b.name;
    """,


    """
    create view finished as
    select *
      from updates
     where b_name is null;
    """,


    """
    create view finished2 as
    select DaemonStartTime                as StartTime
         , last_updated                   as EndTime
         , last_updated - DaemonStartTime as WallDuration
         , total_cpu                      as CpuDuration
         , Cpus                           as Processors
         , MemoryUsage                    as Memory
         , '{VO}'                         as VOName
         , ifnull(GLIDEIN_Site,
                  GLIDEIN_ResourceName)   as Site
         , Machine                        as MachineName
      from finished;
    """.format(VO="OSG"),


    """
    create view updated as
    select *
         , next_CPUsUsage * elapsed_interval as next_cpu
         , max(MemoryUsage,next_MemoryUsage) as next_mem
      from updates
     where b_name is not null;
    """,


    """
    create view new_jobs as
    select b.*
--    from inbox b
      from pslot_totals b
      left join jobs a
        on a.name = b.name
     where a.name is null;
    """,
]


# query collector for machine (startd) ads

def query_current_attrs():
    import htcondor
    pool = 'flock.opensciencegrid.org' #:9618
    coll = htcondor.Collector(pool)

    filter_cond = 'SlotType != "Static"'
    #filter_cond += ' && IsOsgVoContainer =?= True'

    ads = coll.query(ad_type=htcondor.AdTypes.Startd, projection=want_attrs,
                     constraint=filter_cond)
    return ads


def get_db():
    dbpath = 'data.db'
    db_exists = os.path.exists(dbpath)

    sqldb = sqlite3.connect(dbpath)
    if not db_exists:
        for sql in schema_sql:
            sqldb.execute(sql)
        sqldb.commit()

    return sqldb


def eval_expr(x):
    if isinstance(x, classad.classad.ExprTree):
        x = x.eval()
    if isinstance(x, list):
        x = "\t".join(x)
    return x

def qmarks(n):
    return ",".join(["?"] * n)

def write_ads_to_sqlite(sqldb, ads, current_ts):
    print("Writing new ads to inbox")

    n_attrs = len(want_attrs) + 1
    insert_sql = "insert into inbox values (%s)" % qmarks(n_attrs)

    def job2vals(job):
        return [current_ts] + list(map(eval_expr, map(job.get, want_attrs)))

    rc = sqldb.executemany(insert_sql, map(job2vals, ads)).rowcount

    print("- inserted %s rows into inbox" % rc)
    print()


def get_pslots_children(ads):
    for ad in ads:
        if 'ChildName' in ad:
            yield ad['Name'], ad['ChildName']


def get_pslots_dslots(items):
    for pslot, dslots in items:
        for dslot in dslots:
            yield pslot, dslot

def get_pslots_dslots2(ads):
    for ad in ads:
        if 'ChildName' in ad:
            for dslot in ad['ChildName']:
                yield ad['Name'], dslot

def update_slots_info(sqldb, ads):
    print("Updating slot info")

    delete_sql = "delete from slots;"
    insert_sql = "insert into slots values (?,?);"

    rc1 = sqldb.execute(delete_sql).rowcount
    rc2 = sqldb.executemany(insert_sql, get_pslots_dslots2(ads)).rowcount

    print("- deleted %s rows from slots" % rc1)
    print("- inserted %s rows into slots" % rc2)
    print()


def detect_finished_jobs(sqldb, current_ts):
    print("Detecting finished jobs")

    dead_cutoff = current_ts - DONE_IF_NOT_SEEN_AFTER

    insert_sql = """
        insert into outbox (%s)
        select *
          from finished2
         where EndTime < ?
    """ % ", ".join(send_attrs)

    delete_sql = """
        delete from jobs
         where exists ( select 1
                          from finished b
                         where jobs.name = b.name
                           and b.last_updated < ?);
    """

    rc1 = sqldb.execute(insert_sql, (dead_cutoff,)).rowcount
    rc2 = sqldb.execute(delete_sql, (dead_cutoff,)).rowcount

    print("- inserted %s rows into outbox" % rc1)
    print("- deleted %s rows from jobs" % rc2)
    print()


def update_active_jobs(sqldb):
    print("Updating active jobs")

    # TODO: simplify with UPDATE FROM syntax after SQLite 3.33.0 (2020-08-14)
    update_sql = """
        update jobs
           set last_updated = (
                        select next_updated
                          from updated b
                         where jobs.name = b.name),
               total_cpu = total_cpu + (
                        select next_cpu
                          from updated b
                         where jobs.name = b.name),
               MemoryUsage = (
                        select next_mem
                          from updated b
                         where jobs.name = b.name)
         where exists ( select 1
                          from inbox b
                         where jobs.name = b.name);
    """

    delete_sql = """
        delete from inbox
         where exists ( select 1
                          from jobs a
                         where a.name = inbox.name);
    """

    rc1 = sqldb.execute(update_sql).rowcount
    rc2 = sqldb.execute(delete_sql).rowcount

    print("- updated %s rows from jobs" % rc1)
    print("- deleted %s rows from inbox" % rc2)
    print()



def detect_new_jobs(sqldb, current_ts):
    print("Detecting new jobs...")

    insert_sql = """
        insert into jobs
        select *
             , (? - DaemonStartTime) * CPUsUsage as total_cpu
          from new_jobs;
    """

    delete_sql = """
        delete from inbox;
    """

    rc1 = sqldb.execute(insert_sql, (current_ts,)).rowcount

    # XXX: not before update_active_jobs
    rc2 = sqldb.execute(delete_sql).rowcount

    print("- inserted %s rows into jobs" % rc1)
    print("- deleted %s rows from inbox" % rc2)
    print()



def query_and_update_db():
    current_ts = int(time.time())
    ads = query_current_attrs()

    sqldb = get_db()
    write_ads_to_sqlite(sqldb, ads, current_ts)
    update_slots_info(sqldb, ads)

    detect_finished_jobs(sqldb, current_ts)
    update_active_jobs(sqldb)
    detect_new_jobs(sqldb, current_ts) # XXX: this step must go last
    sqldb.commit()


def send_updates():
    # TODO: generate & send records to gracc from outbox table
    pass


def main():
    query_and_update_db()
    send_updates()


if __name__ == '__main__':
    main()


